# enkibot/core/bot.py
# EnkiBot: Advanced Multilingual Telegram AI Assistant
# Copyright (C) 2025 Yael Demedetskaya <yaelkroy@gmail.com>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program. If not, see <https://www.gnu.org/licenses/>.

# ==================================================================================================
# === EnkiBot - Main Bot Logic ===
# ==================================================================================================

# print(f"***** EXECUTING BOT.PY - VERSION: {__file__} *****") 

import logging
import json
import os
import re
import asyncio
from typing import Dict, Any, Optional, Tuple, List 

from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes, ConversationHandler
from telegram.constants import ChatAction

from langdetect import detect, DetectorFactory, detect_langs # Import detect_langs
from langdetect.lang_detect_exception import LangDetectException

from enkibot import config 
from enkibot.utils.database import DatabaseManager
from enkibot.core.llm_services import LLMServices
from enkibot.modules.intent_recognizer import IntentRecognizer
from enkibot.modules.profile_manager import ProfileManager
from enkibot.modules.api_router import ApiRouter
from enkibot.modules.response_generator import ResponseGenerator

try:
    DetectorFactory.seed = 0 
except Exception as e:
    logging.warning(f"Could not seed DetectorFactory (this is okay if it's already seeded): {e}")

logger = logging.getLogger(__name__)
ASK_CITY = 1

class EnkiBot:
    def __init__(self, application: Application):
        logger.info("EnkiBot __init__ STARTING")

        self.application = application
        self.db_manager = DatabaseManager(config.DB_CONNECTION_STRING)
        self.llm_services = LLMServices(
            openai_api_key=config.OPENAI_API_KEY, openai_model_id=config.OPENAI_MODEL_ID,
            groq_api_key=config.GROQ_API_KEY, groq_model_id=config.GROQ_MODEL_ID, groq_endpoint_url=config.GROQ_ENDPOINT_URL,
            openrouter_api_key=config.OPENROUTER_API_KEY, openrouter_model_id=config.OPENROUTER_MODEL_ID, openrouter_endpoint_url=config.OPENROUTER_ENDPOINT_URL,
            google_ai_api_key=config.GOOGLE_AI_API_KEY, google_ai_model_id=config.GOOGLE_AI_MODEL_ID
        )
        self.intent_recognizer = IntentRecognizer(self.llm_services)
        self.profile_manager = ProfileManager(self.llm_services, self.db_manager)
        self.api_router = ApiRouter(
            weather_api_key=config.WEATHER_API_KEY, news_api_key=config.NEWS_API_KEY,
            llm_services=self.llm_services
        )
        self.response_generator = ResponseGenerator(self.llm_services, self.db_manager, self.intent_recognizer)

        self.language_packs: Dict[str, Dict[str, Any]] = {}
        self.llm_prompt_sets: Dict[str, Dict[str, Dict[str, str]]] = {}
        self.response_strings: Dict[str, Dict[str, str]] = {}
        
        self.current_lang: str = config.DEFAULT_LANGUAGE
        self.current_llm_prompt_sets: Dict[str, Dict[str, str]] = {}
        self.current_response_strings: Dict[str, str] = {}
        self.current_lang_pack_full: Dict[str, Any] = {}

        self._load_language_packs()
        self.pending_action_data: Dict[int, Dict[str, Any]] = {}
        logger.info("EnkiBot __init__ COMPLETED")

    def _load_language_packs(self):
        self.language_packs = {}
        self.llm_prompt_sets = {}
        self.response_strings = {}
        if not os.path.exists(config.LANGUAGE_PACKS_DIR):
            logger.error(f"Language packs directory not found: {config.LANGUAGE_PACKS_DIR}")
            try:
                os.makedirs(config.LANGUAGE_PACKS_DIR, exist_ok=True)
                logger.info(f"Created language packs directory: {config.LANGUAGE_PACKS_DIR}")
            except OSError as e:
                logger.error(f"Could not create language packs directory {config.LANGUAGE_PACKS_DIR}: {e}")
        for lang_file in os.listdir(config.LANGUAGE_PACKS_DIR):
            if lang_file.endswith(".json"):
                lang_code = lang_file[:-5]
                file_path = os.path.join(config.LANGUAGE_PACKS_DIR, lang_file)
                try:
                    with open(file_path, 'r', encoding='utf-8-sig') as f: 
                        pack_content = json.load(f)
                        self.language_packs[lang_code] = pack_content
                        self.llm_prompt_sets[lang_code] = pack_content.get("prompts", {})
                        self.response_strings[lang_code] = pack_content.get("responses", {})
                        logger.info(f"Successfully loaded language pack: {lang_code} from {file_path}")
                except json.JSONDecodeError as jde:
                    logger.error(f"Error decoding JSON from language file: {lang_file}. Error: {jde.msg} at line {jde.lineno} col {jde.colno} (char {jde.pos})", exc_info=False)
                except Exception as e:
                    logger.error(f"Error loading language file {lang_file}: {e}", exc_info=True)
        self._set_current_language_internals(config.DEFAULT_LANGUAGE)

    def _set_current_language_internals(self, lang_code_to_set: str):
        primary_fallback_lang = config.DEFAULT_LANGUAGE 
        secondary_fallback_lang = "ru"
        chosen_lang_code = lang_code_to_set

        if chosen_lang_code not in self.language_packs:
            logger.warning(f"Language pack for initially requested '{chosen_lang_code}' not found.")
            if primary_fallback_lang in self.language_packs:
                logger.info(f"Falling back to primary fallback: '{primary_fallback_lang}'.")
                chosen_lang_code = primary_fallback_lang
            elif secondary_fallback_lang in self.language_packs:
                logger.info(f"Primary fallback '{primary_fallback_lang}' not found. Falling back to secondary: '{secondary_fallback_lang}'.")
                chosen_lang_code = secondary_fallback_lang
            elif self.language_packs: 
                first_available = next(iter(self.language_packs))
                logger.error(f"Fallbacks ('{primary_fallback_lang}', '{secondary_fallback_lang}') not found. Using first available: '{first_available}'.")
                chosen_lang_code = first_available
            else: 
                logger.critical("CRITICAL: No language packs loaded at all. Bot will not function correctly.")
                self.current_lang = "none" 
                self.current_lang_pack_full = {}
                self.current_llm_prompt_sets = {}
                self.current_response_strings = {}
                return

        self.current_lang = chosen_lang_code
        self.current_lang_pack_full = self.language_packs.get(chosen_lang_code, {})
        self.current_llm_prompt_sets = self.llm_prompt_sets.get(chosen_lang_code, {})
        self.current_response_strings = self.response_strings.get(chosen_lang_code, {})
        
        if not self.current_llm_prompt_sets and not self.current_response_strings:
             logger.error(f"Language '{self.current_lang}' pack loaded, but it has no 'prompts' or 'responses' sections defined.")
        else:
            logger.info(f"Successfully set current language context to: '{self.current_lang}'")

    async def _create_and_load_language_pack(self, new_lang_code: str, update_context: Optional[Update] = None) -> bool:
        logger.info(f"Attempting to create language pack for new language: {new_lang_code}")
        english_pack_key = "en"
        if english_pack_key not in self.language_packs:
            logger.error(f"Cannot create new language pack: Source English ('{english_pack_key}') pack not found.")
            if update_context and update_context.effective_message:
                 await update_context.effective_message.reply_text("My apologies, I'm having trouble setting up support for this language right now as my base language files are missing.")
            return False

        english_pack_content_str = json.dumps(self.language_packs[english_pack_key], ensure_ascii=False, indent=2)
        target_language_name = new_lang_code 

        translation_system_prompt = (
             f"You are an expert translation AI. Your task is to translate a complete JSON language pack from English to {target_language_name} (language code: {new_lang_code}).\n"
            "You MUST maintain the original JSON structure and all original keys (e.g., \"prompts\", \"responses\", \"weather_conditions_map\", \"days_of_week\", and all keys within them). Only translate the string values associated with the keys.\n"
            "The output MUST be a single, valid JSON object and nothing else. Do not add any explanatory text, comments, or markdown before or after the JSON.\n"
            "Ensure all translated strings are appropriate for a friendly AI assistant and are natural-sounding in the target language. Pay special attention to escaping characters within JSON strings if necessary (e.g. double quotes inside a string should be \\\", newlines as \\n)."
        )
        translation_user_prompt = f"Translate the following English JSON language pack to {target_language_name} ({new_lang_code}):\n\n{english_pack_content_str}"
        
        messages_for_api = [{"role": "system", "content": translation_system_prompt}, {"role": "user", "content": translation_user_prompt}]
        response_format_arg = {"response_format": {"type": "json_object"}}
        
        translated_content_str: Optional[str] = None
        try:
            translated_content_str = await self.llm_services.call_openai_llm(
                messages_for_api, model_id=config.OPENAI_MODEL_ID, 
                temperature=0.1, max_tokens=4000, **response_format_arg
            )
        except Exception as e:
            logger.error(f"LLM call itself failed during translation for {new_lang_code}: {e}", exc_info=True)
            if update_context and update_context.effective_message:
                 await update_context.effective_message.reply_text(self._get_response_string("language_pack_creation_failed_fallback"))
            return False

        if not translated_content_str:
            logger.error(f"LLM failed to provide a translation string for {new_lang_code}.")
            if update_context and update_context.effective_message:
                 await update_context.effective_message.reply_text(self._get_response_string("language_pack_creation_failed_fallback"))
            return False
        
        clean_response = translated_content_str.strip() 
        try:
            match = re.search(r"```json\s*(.*?)\s*```", clean_response, re.DOTALL | re.IGNORECASE)
            if match: clean_response = match.group(1).strip()
            else:
                if clean_response.startswith("```json"): clean_response = clean_response[7:]
                if clean_response.endswith("```"): clean_response = clean_response[:-3]
            clean_response = clean_response.strip()
            
            logger.debug(f"Attempting to parse cleaned LLM translation for {new_lang_code}: '{clean_response[:300]}...'")
            translated_pack_content = json.loads(clean_response) 
            
            if not all(k in translated_pack_content for k in ["prompts", "responses", "weather_conditions_map", "days_of_week"]):
                logger.error(f"Translated pack for {new_lang_code} is missing core top-level keys. Aborting save.")
                raise ValueError("Translated JSON missing core keys.")

            new_pack_path = os.path.join(config.LANGUAGE_PACKS_DIR, f"{new_lang_code}.json")
            with open(new_pack_path, 'w', encoding='utf-8') as f: 
                json.dump(translated_pack_content, f, ensure_ascii=False, indent=2)
            logger.info(f"Successfully created and saved new language pack: {new_lang_code}.json")
            
            self.language_packs[new_lang_code] = translated_pack_content
            self.llm_prompt_sets[new_lang_code] = translated_pack_content.get("prompts", {})
            self.response_strings[new_lang_code] = translated_pack_content.get("responses", {})
            logger.info(f"New language pack for {new_lang_code} is now available at runtime.")
            return True
        except json.JSONDecodeError as jde:
            logger.error(
                f"Failed to decode LLM translation JSON for {new_lang_code}. Error: {jde.msg} "
                f"at L{jde.lineno} C{jde.colno} (char {jde.pos}). "
                f"Nearby: '{clean_response[max(0, jde.pos-50):jde.pos+50]}'", 
                exc_info=False 
            )
            log_limit = 3000
            full_resp_to_log = translated_content_str 
            if len(full_resp_to_log) < log_limit: logger.debug(f"Full problematic translated content for {new_lang_code}:\n{full_resp_to_log}")
            else: logger.debug(f"Problematic translated content (first {log_limit} chars) for {new_lang_code}:\n{full_resp_to_log[:log_limit]}")
            if update_context and update_context.effective_message:
                await update_context.effective_message.reply_text(self._get_response_string("language_pack_creation_failed_fallback"))
            return False
        except Exception as e:
            logger.error(f"Error processing/saving new lang pack for {new_lang_code}: {e}", exc_info=True)
            if update_context and update_context.effective_message: 
                await update_context.effective_message.reply_text(self._get_response_string("language_pack_creation_failed_fallback"))
            return False

    async def _detect_language_and_set_prompts(self, 
                                               current_message_text: Optional[str], 
                                               chat_id: Optional[int], # Added chat_id
                                               update_context: Optional[Update] = None) -> str:
        
        CONFIDENCE_THRESHOLD = 0.60  # Minimum probability for a detected language
        NUM_RECENT_MESSAGES_FOR_DETECTION = 3 
        MIN_AGGREGATED_TEXT_LENGTH = 20 # Min length of combined text to run detect_langs

        # Start with the current session's language or the primary default.
        candidate_lang_code = self.current_lang if self.current_lang != "none" else config.DEFAULT_LANGUAGE
        
        texts_for_detection: List[str] = []
        if current_message_text and current_message_text.strip():
            texts_for_detection.append(current_message_text.strip())

        # Fetch recent messages if current message is short or for general robustness
        if chat_id and (not texts_for_detection or len(texts_for_detection[0]) < 50): 
            logger.debug(f"Fetching last {NUM_RECENT_MESSAGES_FOR_DETECTION} messages from chat {chat_id} for lang detection.")
            try:
                if self.db_manager: # Ensure db_manager is initialized
                    recent_messages = await self.db_manager.get_recent_chat_texts(chat_id, limit=NUM_RECENT_MESSAGES_FOR_DETECTION)
                    if recent_messages:
                        texts_for_detection.extend(recent_messages) 
                        logger.debug(f"Fetched {len(recent_messages)} recent messages. Total texts for detection: {len(texts_for_detection)}")
                else:
                    logger.warning("db_manager not available in _detect_language_and_set_prompts.")
            except Exception as e:
                logger.error(f"Error fetching recent chat texts for language detection: {e}", exc_info=True)
        
        aggregated_text = " . ".join(reversed(texts_for_detection)).strip() # Most recent last
        
        detected_languages_with_probs: List[Any] = [] 
        attempted_new_detection_on_aggregated = False

        if aggregated_text and len(aggregated_text) >= MIN_AGGREGATED_TEXT_LENGTH:
            attempted_new_detection_on_aggregated = True
            try:
                # DetectorFactory.seed = 0 # Re-seeding here might be too frequent. Seed once at module level.
                detected_languages_with_probs = detect_langs(aggregated_text)
                logger.info(f"LangDetect results on aggregated text (len {len(aggregated_text)}): {detected_languages_with_probs}")
            except LangDetectException:
                logger.warning(f"LangDetectException on aggregated text. Current candidate: '{candidate_lang_code}'.")
            except Exception as e: 
                logger.error(f"Unexpected error during langdetect.detect_langs: {e}. Current candidate: '{candidate_lang_code}'.")
        else:
            logger.info(f"Aggregated text too short or empty ('{aggregated_text[:50]}...'). Using current candidate: '{candidate_lang_code}'.")

        # Process detected languages to choose a candidate
        chosen_lang_from_detection = None
        if detected_languages_with_probs:
            for lang_obj in sorted(detected_languages_with_probs, key=lambda x: x.prob, reverse=True): # Ensure sorted by prob
                lang_code_detected = lang_obj.lang
                lang_prob = lang_obj.prob
                logger.debug(f"Checking detected lang: {lang_code_detected} with prob: {lang_prob:.3f}")

                if lang_prob >= CONFIDENCE_THRESHOLD:
                    if lang_code_detected in self.language_packs:
                        logger.info(f"Prioritizing existing pack for detected language '{lang_code_detected}' (prob: {lang_prob:.3f}).")
                        chosen_lang_from_detection = lang_code_detected
                        break # Found a good existing pack
                    elif chosen_lang_from_detection is None: # No existing pack found yet for high confidence, take the first one
                        chosen_lang_from_detection = lang_code_detected
                        logger.info(f"High-confidence lang '{lang_code_detected}' (prob {lang_prob:.3f}) is first candidate for creation.")
                else:
                    logger.debug(f"Detected language '{lang_code_detected}' prob {lang_prob:.3f} below threshold {CONFIDENCE_THRESHOLD}. Stopping checks.")
                    break # Since list is sorted, subsequent probs will also be too low
        
        if chosen_lang_from_detection:
            candidate_lang_code = chosen_lang_from_detection
            logger.info(f"Candidate language after detection logic: '{candidate_lang_code}'")
        else:
            logger.info(f"No suitable language found from detection (or detection not run). Sticking with previous candidate: '{candidate_lang_code}'")


        # Attempt to set/create pack for the final candidate_lang_code
        if candidate_lang_code not in self.language_packs:
            # Only attempt creation if we had a basis for choosing this language (e.g., from detection)
            # or if the initial candidate_lang_code (current/default) was itself the one missing.
            if attempted_new_detection_on_aggregated or candidate_lang_code != (self.current_lang if self.current_lang != "none" else config.DEFAULT_LANGUAGE):
                logger.warning(f"Language '{candidate_lang_code}' pack not found. Attempting to create one.")
                if await self._create_and_load_language_pack(candidate_lang_code, update_context=update_context):
                    self._set_current_language_internals(candidate_lang_code)
                else:
                    logger.warning(f"Failed to create pack for '{candidate_lang_code}'. Applying prioritized fallbacks.")
                    self._set_current_language_internals(config.DEFAULT_LANGUAGE) # Triggers en -> ru -> first available
            else:
                # No new detection, current/default pack missing
                logger.info(f"Pack for current/default candidate '{candidate_lang_code}' is missing. Applying fallbacks directly.")
                self._set_current_language_internals(config.DEFAULT_LANGUAGE) # Start fallback chain
        else: # Pack for candidate_lang_code already exists
            self._set_current_language_internals(candidate_lang_code)
        
        return self.current_lang

    async def log_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        # logger.info("EnkiBot.log_message CALLED")
        if not update.message or not update.message.text or not update.effective_user: 
            logger.debug("log_message: Skipping due to missing message, text, or user.")
            return
        
        chat_id = update.effective_chat.id
        user = update.effective_user
        message = update.message

        if config.ALLOWED_GROUP_IDS and chat_id not in config.ALLOWED_GROUP_IDS:
            logger.debug(f"log_message: Skipping message from chat {chat_id}, not in allowed group IDs.")
            return

        action_taken = await self.db_manager.log_chat_message_and_upsert_user(
            chat_id=chat_id, user_id=user.id, username=user.username,
            first_name=user.first_name, last_name=user.last_name,
            message_id=message.message_id, message_text=message.text,
            preferred_language=self.current_lang 
        )
        logger.info(f"Message from user {user.id} logged. Profile action: {action_taken}.")

        name_var_prompts = self._get_llm_prompt_set("name_variation_generator")
        if action_taken and action_taken.lower() == "insert" and name_var_prompts:
            logger.info(f"New user {user.id} ({user.first_name}). Queuing name variation generation.")
            asyncio.create_task(self.profile_manager.populate_name_variations_with_llm(
                user_id=user.id, first_name=user.first_name, last_name=user.last_name, username=user.username,
                system_prompt=name_var_prompts["system"], 
                user_prompt_template=name_var_prompts.get("user","Generate for: {name_info}")
            ))

        profile_create_prompts = self._get_llm_prompt_set("profile_creator")
        profile_update_prompts = self._get_llm_prompt_set("profile_updater")
        if message.text and len(message.text.strip()) > 10:
            if profile_create_prompts and profile_update_prompts:
                logger.info(f"Message from user {user.id} meets criteria for profile analysis. Queuing task.")
                asyncio.create_task(self.profile_manager.analyze_and_update_user_profile(
                    user_id=user.id, message_text=message.text,
                    create_system_prompt=profile_create_prompts["system"],
                    create_user_prompt_template=profile_create_prompts.get("user","Analyze: {message_text}"),
                    update_system_prompt=profile_update_prompts["system"],
                    update_user_prompt_template=profile_update_prompts.get("user","Update based on: {message_text} with existing: {current_profile_notes}")
                ))
            else: 
                logger.warning(f"Profile prompts missing for lang '{self.current_lang}'. Skipping profile analysis for user {user.id}.")

    async def handle_message(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> Optional[int]:
        # logger.info(f"DIAGNOSTIC (handle_message START): Current lang before detection: {self.current_lang} for chat {update.effective_chat.id if update.effective_chat else 'N/A'}")
        if not update.message or not update.message.text or not update.effective_chat or not update.effective_user: return None 
        
        # 1. Detect language & set context
        await self._detect_language_and_set_prompts(
            update.message.text, 
            chat_id=update.effective_chat.id,
            update_context=update
        )
        # logger.info(f"DIAGNOSTIC (handle_message after detect): Lang set to: {self.current_lang} for user {update.effective_user.id}")
        
        # 2. Log message
        if hasattr(self, 'log_message') and callable(getattr(self, 'log_message')): 
            await self.log_message(update, context)
        else: 
            logger.critical("CRITICAL: log_message method not found! Logging skipped.")
            if update.message: 
                 await update.message.reply_text("An internal error occurred (L). Please try again later.")
            return None

        # 3. Handle pending actions
        pending_action = self.pending_action_data.pop(update.effective_chat.id, None)
        if pending_action and pending_action["action_type"] == "ask_city_weather":
            city_name = update.message.text
            logger.info(f"Received city '{city_name}' for pending weather request.")
            await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
            weather_report = await self.api_router.get_weather_data( 
                location=city_name, forecast_type=pending_action["forecast_type"], 
                days=pending_action["days"], lang_pack_full=self.current_lang_pack_full )
            await update.message.reply_text(weather_report, reply_to_message_id=pending_action["original_message_id"])
            return ConversationHandler.END 

        user_msg_txt = update.message.text
        user_msg_txt_lower = user_msg_txt.lower()

        # 4. Check trigger
        if not await self._is_triggered(update, context, user_msg_txt_lower): return None

        # 5. Master Intent Classification
        master_intent_prompts = self._get_llm_prompt_set("master_intent_classifier")
        master_intent = "UNKNOWN_INTENT"
        if master_intent_prompts and "system" in master_intent_prompts:
            user_template_for_master = master_intent_prompts.get("user","{text_to_classify}")
            master_intent = await self.intent_recognizer.classify_master_intent(
                text=user_msg_txt, lang_code=self.current_lang,
                system_prompt=master_intent_prompts["system"], user_prompt_template=user_template_for_master )
        else: logger.error(f"Master intent classification prompt set missing/malformed for lang '{self.current_lang}'.")
        
        logger.info(f"Master Intent for '{user_msg_txt[:50]}...' classified as: {master_intent}")

        # 6. Route based on Master Intent
        if master_intent == "WEATHER_QUERY":
            state = await self._handle_weather_intent(update, context, user_msg_txt)
            return state 
        elif master_intent == "NEWS_QUERY": await self._handle_news_intent(update, context, user_msg_txt)
        elif master_intent == "MESSAGE_ANALYSIS_QUERY": await self._handle_message_analysis_query(update, context, user_msg_txt)
        elif master_intent in ["USER_PROFILE_QUERY", "GENERAL_CHAT", "UNKNOWN_INTENT"]:
            await self._handle_user_profile_query_or_general_chat(update, context, user_msg_txt, master_intent)
        else: 
            logger.warning(f"Unhandled master intent type: {master_intent}. Falling back to general.")
            await self._handle_user_profile_query_or_general_chat(update, context, user_msg_txt, "UNKNOWN_INTENT")
        return None
    
    def _get_llm_prompt_set(self, key: str) -> Optional[Dict[str, str]]:
        current_prompts_to_check = self.current_llm_prompt_sets
        prompt_set = current_prompts_to_check.get(key)
        primary_fallback_lang = config.DEFAULT_LANGUAGE
        secondary_fallback_lang = "ru"

        if not prompt_set: 
            logger.debug(f"LLM prompt set key '{key}' not in current lang '{self.current_lang}'. Trying '{primary_fallback_lang}'.")
            current_prompts_to_check = self.llm_prompt_sets.get(primary_fallback_lang, {})
            prompt_set = current_prompts_to_check.get(key)
            if not prompt_set and primary_fallback_lang != secondary_fallback_lang: 
                 logger.debug(f"LLM prompt set key '{key}' not in '{primary_fallback_lang}'. Trying '{secondary_fallback_lang}'.")
                 current_prompts_to_check = self.llm_prompt_sets.get(secondary_fallback_lang, {})
                 prompt_set = current_prompts_to_check.get(key)
        
        if not prompt_set:
            logger.error(f"LLM prompt set for key '{key}' ultimately not found.")
            return None
        if not isinstance(prompt_set, dict) or "system" not in prompt_set: 
            logger.error(f"LLM prompt set for key '{key}' (found in lang or fallback) is malformed: {prompt_set}")
            return None
        return prompt_set

    def _get_response_string(self, key: str, default_value: Optional[str] = None, **kwargs) -> str:
        raw_string = self.current_response_strings.get(key)
        lang_tried = self.current_lang
        primary_fallback_lang = config.DEFAULT_LANGUAGE
        secondary_fallback_lang = "ru"

        if raw_string is None: 
            lang_tried = primary_fallback_lang
            raw_string = self.response_strings.get(primary_fallback_lang, {}).get(key)
            if raw_string is None and primary_fallback_lang != secondary_fallback_lang: 
                lang_tried = secondary_fallback_lang
                raw_string = self.response_strings.get(secondary_fallback_lang, {}).get(key)

        if raw_string is None: 
            if default_value is not None: raw_string = default_value
            else: logger.error(f"Response string for key '{key}' ultimately not found. Using placeholder."); raw_string = f"[[Missing response: {key}]]"
        
        try:
            return raw_string.format(**kwargs) if kwargs else raw_string
        except KeyError as e:
            logger.error(f"Missing format key '{e}' in response string for key '{key}' (lang tried: {lang_tried}, raw: '{raw_string}')")
            english_raw = self.response_strings.get("en", {}).get(key, f"[[Format error & missing English for key: {key}]]")
            try: return english_raw.format(**kwargs) if kwargs else english_raw
            except KeyError: return f"[[Formatting error for response key: {key} - check placeholders]]"

    async def _is_triggered(self, update: Update, context: ContextTypes.DEFAULT_TYPE, user_msg_txt_lower: str) -> bool:
        # ... (implementation with enhanced logging for group ID check from message #26) ...
        if not update.message or not context.bot:
            # logger.debug("_is_triggered: False (no message or bot context)") # Can be too verbose
            return False
        
        current_chat_id = update.effective_chat.id
        is_group = update.message.chat.type in ['group', 'supergroup']

        if not is_group:
            # logger.debug(f"_is_triggered: True (private chat with user {update.effective_user.id if update.effective_user else 'Unknown'})")
            return True

        # --- Group Chat Logic ---
        # logger.info(f"DIAGNOSTIC (_is_triggered): Group Chat ID: {current_chat_id}, Allowed Set: {config.ALLOWED_GROUP_IDS}")
        if config.ALLOWED_GROUP_IDS: 
            if current_chat_id not in config.ALLOWED_GROUP_IDS:
                # logger.info(f"_is_triggered: False (group {current_chat_id} not in ALLOWED_GROUP_IDS: {config.ALLOWED_GROUP_IDS})")
                return False
        
        bot_username_lower = getattr(context.bot, 'username', "").lower() if getattr(context.bot, 'username', None) else ""
        is_at_mentioned = bool(bot_username_lower and f"@{bot_username_lower}" in user_msg_txt_lower)
        is_nickname_mentioned = False
        for nick in config.BOT_NICKNAMES_TO_CHECK:
            if re.search(r'\b' + re.escape(nick.lower()) + r'\b', user_msg_txt_lower, re.I):
                is_nickname_mentioned = True; break
        
        is_bot_mentioned = is_at_mentioned or is_nickname_mentioned
        is_reply_to_bot = (update.message.reply_to_message and 
                           update.message.reply_to_message.from_user and
                           update.message.reply_to_message.from_user.id == context.bot.id)
        
        final_trigger_decision = is_bot_mentioned or is_reply_to_bot
        # logger.info(f"_is_triggered (Group: {current_chat_id}): Text='{user_msg_txt_lower[:30]}...' @Mention={is_at_mentioned}, NickMention={is_nickname_mentioned}, ReplyToBot={is_reply_to_bot} => Trigger={final_trigger_decision}")
        return final_trigger_decision

    async def _handle_message_analysis_query(self, update: Update, context: ContextTypes.DEFAULT_TYPE, user_msg_txt: str) -> bool:
        # ... (implementation as in message #26, ensuring prompt fetching is robust) ...
        if not (update.message and update.message.reply_to_message and 
                update.message.reply_to_message.text and 
                update.message.reply_to_message.from_user and
                context.bot and update.message.reply_to_message.from_user.id != context.bot.id):
            return False
        logger.info("Processing MESSAGE_ANALYSIS_QUERY.")
        await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
        original_text = update.message.reply_to_message.text
        question_for_analysis = user_msg_txt
        bot_username_lower = getattr(context.bot, 'username', "").lower() if getattr(context.bot, 'username', None) else ""
        cleaned_question = user_msg_txt.lower()
        for nick in config.BOT_NICKNAMES_TO_CHECK + ([f"@{bot_username_lower}"] if bot_username_lower else []):
            cleaned_question = cleaned_question.replace(nick.lower(), "").strip()
        if len(cleaned_question) < 5: question_for_analysis = self._get_response_string("replied_message_default_question")
        analyzer_prompts = self._get_llm_prompt_set("replied_message_analyzer")
        if not analyzer_prompts : logger.error("Prompt set for replied message analysis is missing."); await update.message.reply_text(self._get_response_string("generic_error_message")); return True
        analysis_result = await self.response_generator.analyze_replied_message(
            original_text=original_text, user_question=question_for_analysis,
            system_prompt=analyzer_prompts["system"], user_prompt_template=analyzer_prompts.get("user") )
        await update.message.reply_text(analysis_result); return True

    async def _handle_weather_intent(self, update: Update, context: ContextTypes.DEFAULT_TYPE, user_msg_txt: str) -> Optional[int]:
        # ... (implementation as in message #26, ensure prompt fetching is robust) ...
        logger.info(f"Handling WEATHER_QUERY: '{user_msg_txt}'")
        await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
        weather_analysis_prompts = self._get_llm_prompt_set("weather_intent_analyzer")
        location_extract_prompts = self._get_llm_prompt_set("location_extractor")
        if not (weather_analysis_prompts and location_extract_prompts):
            logger.error("Weather intent prompts are missing or malformed."); await update.message.reply_text(self._get_response_string("generic_error_message")); return None 
        intent_data = await self.intent_recognizer.analyze_weather_request_with_llm(
            text=user_msg_txt, lang_code=self.current_lang, system_prompt=weather_analysis_prompts["system"], user_prompt_template=weather_analysis_prompts.get("user") )
        city = await self.intent_recognizer.extract_location_with_llm(
            text=user_msg_txt, lang_code=self.current_lang, system_prompt=location_extract_prompts["system"], user_prompt_template=location_extract_prompts.get("user") )
        if city:
            weather_report = await self.api_router.get_weather_data(location=city, forecast_type=intent_data.get("type", "current"), days=intent_data.get("days", 7), lang_pack_full=self.current_lang_pack_full )
            await update.message.reply_text(weather_report); return None 
        else:
            self.pending_action_data[update.effective_chat.id] = { "action_type": "ask_city_weather", "forecast_type": intent_data.get("type", "current"), "days": intent_data.get("days", 7), "original_message_id": update.message.message_id }
            await update.message.reply_text(self._get_response_string("weather_ask_city")); return ASK_CITY

    async def _handle_news_intent(self, update: Update, context: ContextTypes.DEFAULT_TYPE, user_msg_txt: str) -> None:
        # ... (implementation as in message #26, ensure prompt fetching is robust) ...
        logger.info(f"Handling NEWS_QUERY: '{user_msg_txt}'")
        await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
        news_topic_prompts = self._get_llm_prompt_set("news_topic_extractor")
        if not news_topic_prompts: logger.error("News topic extraction prompt is missing or malformed."); await update.message.reply_text(self._get_response_string("generic_error_message")); return
        topic = await self.intent_recognizer.extract_news_topic_with_llm(
            text=user_msg_txt, lang_code=self.current_lang, system_prompt=news_topic_prompts["system"], user_prompt_template=news_topic_prompts.get("user") )
        news_report = await self.api_router.get_latest_news( query=topic, lang_code=self.current_lang, response_strings=self.current_response_strings )
        await update.message.reply_text(news_report, disable_web_page_preview=True)

    async def _handle_user_profile_query_or_general_chat(self, update: Update, context: ContextTypes.DEFAULT_TYPE, user_msg_txt: str, master_intent: str) -> None:
        # ... (implementation as in message #26, ensure prompt fetching is robust) ...
        logger.info(f"Handling {master_intent}: '{user_msg_txt}'")
        await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
        main_orchestrator_prompts = self._get_llm_prompt_set("main_orchestrator")
        system_prompt_override = (main_orchestrator_prompts["system"] if main_orchestrator_prompts else "You are EnkiBot, a helpful AI assistant.")
        reply = await self.response_generator.get_orchestrated_llm_response(
            prompt_text=user_msg_txt, chat_id=update.effective_chat.id, user_id=update.effective_user.id, message_id=update.message.message_id, context=context, lang_code=self.current_lang,
            system_prompt_override=system_prompt_override, user_search_ambiguous_response_template=self._get_response_string("user_search_ambiguous_clarification"),
            user_search_not_found_response_template=self._get_response_string("user_search_not_found_in_db") )
        if reply: await update.message.reply_text(reply)
        else: await update.message.reply_text(self._get_response_string("llm_error_fallback"))
        
    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        if not update.effective_user or not update.message: return
        self._set_current_language_internals(config.DEFAULT_LANGUAGE) # For commands, usually best to default
        await update.message.reply_html(self._get_response_string("start", user_mention=update.effective_user.mention_html()))

    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        if not update.message: return
        self._set_current_language_internals(config.DEFAULT_LANGUAGE)
        await update.message.reply_text(self._get_response_string("help"))

    async def news_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
        if not update.message or not update.effective_chat: return
        self._set_current_language_internals(config.DEFAULT_LANGUAGE)
        await context.bot.send_chat_action(chat_id=update.effective_chat.id, action=ChatAction.TYPING)
        report = await self.api_router.get_latest_news(query=None, lang_code=self.current_lang, response_strings=self.current_response_strings)
        await update.message.reply_text(report, disable_web_page_preview=True)

    async def error_handler(self, update: object, context: ContextTypes.DEFAULT_TYPE) -> None:
        logger.error(f'Update "{update}" caused error "{context.error}"', exc_info=True)
        if isinstance(update, Update) and update.effective_chat:
            try:
                error_responses = self.language_packs.get(config.DEFAULT_LANGUAGE, {}).get("responses", {})
                if not error_responses and self.language_packs: error_responses = next(iter(self.language_packs.values()), {}).get("responses", {})
                error_msg = error_responses.get("generic_error_message", "Oops! Something went very wrong on my end. I've logged the issue.")
                await context.bot.send_message(chat_id=update.effective_chat.id, text=error_msg)
            except Exception as e: logger.error(f"CRITICAL: Error sending error message to user: {e}", exc_info=True)
    
    def register_handlers(self, application: Application):
        application.add_handler(CommandHandler("start", self.start_command))
        application.add_handler(CommandHandler("help", self.help_command))
        application.add_handler(CommandHandler("news", self.news_command))
        conv_handler = ConversationHandler(
            entry_points=[MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_message)],
            states={ ASK_CITY: [MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_message)],},
            fallbacks=[], allow_reentry=True 
        )
        application.add_handler(conv_handler)
        application.add_error_handler(self.error_handler)
        logger.info("All Telegram handlers have been registered.")